from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Query
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uvicorn
import os
import uuid
import json
import asyncio
from datetime import datetime
from pathlib import Path
import logging

from config import settings
from parser import ppt_parser, SlideContent, PPTStructure
from agent import knowledge_agent

logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="PPTå†…å®¹æ‰©å±•æ™ºèƒ½ä½“API",
    description="åŸºäºäº‘åŸç”Ÿå’ŒLLMçš„PPTå†…å®¹æ‰©å±•ç³»ç»Ÿ",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path(settings.upload_folder)
UPLOAD_DIR.mkdir(exist_ok=True)

# å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰
file_store = {}
expansion_results = {}


# æ•°æ®æ¨¡å‹
class PPTUploadRequest(BaseModel):
    description: Optional[str] = None


class SlideExpansionRequest(BaseModel):
    slide_numbers: List[int] = Field(default_factory=list)
    expansion_types: List[str] = Field(default_factory=lambda: ["explanation", "examples", "references", "quiz"])


class SearchRequest(BaseModel):
    query: str
    limit: int = 5


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "PPTå†…å®¹æ‰©å±•æ™ºèƒ½ä½“API",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "ä¸Šä¼ PPT": "POST /api/upload",
            "è·å–æ–‡ä»¶åˆ—è¡¨": "GET /api/files",
            "è·å–æ–‡ä»¶è¯¦æƒ…": "GET /api/file/{file_id}",
            "æ‰©å±•å†…å®¹": "POST /api/expand/{file_id}",
            "ä¸‹è½½ç»“æœ": "GET /api/download/{file_id}",
            "æœç´¢å†…å®¹": "POST /api/search"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "parser": "ready",
            "agent": "ready",
            "storage": "ready"
        }
    }


@app.post("/api/upload")
async def upload_ppt(
        file: UploadFile = File(...),
        description: Optional[str] = None
):
    """ä¸Šä¼ PPTæ–‡ä»¶"""
    try:
        logger.info(f"æ”¶åˆ°ä¸Šä¼ è¯·æ±‚: {file.filename}")

        # éªŒè¯æ–‡ä»¶ç±»å‹
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ['.pptx', '.ppt', '.pdf']:
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒPPTã€PPTXå’ŒPDFæ–‡ä»¶")

        # ç”Ÿæˆæ–‡ä»¶ID
        file_id = str(uuid.uuid4())
        filename = f"{file_id}_{file.filename}"
        file_path = UPLOAD_DIR / filename

        # ä¿å­˜æ–‡ä»¶
        file_content = await file.read()
        if len(file_content) > settings.max_upload_size:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤ªå¤§")

        with open(file_path, "wb") as buffer:
            buffer.write(file_content)

        logger.info(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")

        # è§£æPPT
        try:
            structure = ppt_parser.parse_pptx(str(file_path))

            # ä¿å­˜è§£æç»“æœ
            json_path = UPLOAD_DIR / f"{file_id}_parsed.json"
            ppt_parser.save_to_json(structure, str(json_path))

            # å­˜å‚¨åˆ°å†…å­˜
            file_store[file_id] = {
                "file_id": file_id,
                "original_filename": file.filename,
                "file_path": str(file_path),
                "json_path": str(json_path),
                "uploaded_at": datetime.now().isoformat(),
                "file_size": len(file_content),
                "description": description,
                "structure": structure.dict()
            }

            logger.info(f"PPTè§£ææˆåŠŸ: {file_id}, {structure.metadata.total_slides} å¼ å¹»ç¯ç‰‡")

            return {
                "success": True,
                "file_id": file_id,
                "filename": file.filename,
                "total_slides": structure.metadata.total_slides,
                "outline": structure.outline[:10],  # åªè¿”å›å‰10æ¡å¤§çº²
                "message": "æ–‡ä»¶ä¸Šä¼ å’Œè§£ææˆåŠŸ"
            }

        except Exception as e:
            logger.error(f"PPTè§£æå¤±è´¥: {e}")
            # æ¸…ç†æ–‡ä»¶
            if file_path.exists():
                file_path.unlink()
            raise HTTPException(status_code=500, detail=f"PPTè§£æå¤±è´¥: {str(e)}")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@app.get("/api/files")
async def list_files():
    """è·å–æ–‡ä»¶åˆ—è¡¨"""
    files = []
    for file_id, file_info in file_store.items():
        files.append({
            "file_id": file_id,
            "filename": file_info["original_filename"],
            "uploaded_at": file_info["uploaded_at"],
            "total_slides": file_info["structure"]["metadata"]["total_slides"],
            "file_size": file_info["file_size"],
            "description": file_info.get("description")
        })

    # æŒ‰ä¸Šä¼ æ—¶é—´æ’åº
    files.sort(key=lambda x: x["uploaded_at"], reverse=True)

    return {"files": files}


@app.get("/api/file/{file_id}")
async def get_file_info(file_id: str):
    """è·å–æ–‡ä»¶è¯¦æƒ…"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    file_info = file_store[file_id]
    structure = PPTStructure(**file_info["structure"])

    return {
        "file_id": file_id,
        "filename": file_info["original_filename"],
        "uploaded_at": file_info["uploaded_at"],
        "file_size": file_info["file_size"],
        "description": file_info.get("description"),
        "structure": {
            "metadata": structure.metadata.dict(),
            "total_slides": structure.metadata.total_slides,
            "keywords": structure.keywords,
            "outline": structure.outline
        },
        "slides_preview": [
            {
                "slide_number": slide.slide_number,
                "title": slide.title,
                "content_preview": slide.content[0][:100] + "..." if slide.content else "",
                "level": slide.level
            }
            for slide in structure.slides[:10]  # åªè¿”å›å‰10å¼ é¢„è§ˆ
        ]
    }


@app.get("/api/file/{file_id}/slide/{slide_number}")
async def get_slide_detail(file_id: str, slide_number: int):
    """è·å–å•å¼ å¹»ç¯ç‰‡è¯¦æƒ…"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    file_info = file_store[file_id]
    structure = PPTStructure(**file_info["structure"])

    if slide_number < 0 or slide_number >= len(structure.slides):
        raise HTTPException(status_code=404, detail="å¹»ç¯ç‰‡ä¸å­˜åœ¨")

    slide = structure.slides[slide_number]
    return slide.dict()


@app.post("/api/expand/{file_id}")
async def expand_slides(
        file_id: str,
        request: SlideExpansionRequest,
        background_tasks: BackgroundTasks
):
    """æ‰©å±•å¹»ç¯ç‰‡å†…å®¹"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        file_info = file_store[file_id]
        structure = PPTStructure(**file_info["structure"])

        # ç¡®å®šè¦æ‰©å±•çš„å¹»ç¯ç‰‡
        if request.slide_numbers:
            slides_to_expand = [structure.slides[i] for i in request.slide_numbers
                                if 0 <= i < len(structure.slides)]
        else:
            # é»˜è®¤æ‰©å±•æ‰€æœ‰å¹»ç¯ç‰‡
            slides_to_expand = structure.slides

        if not slides_to_expand:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰å¯æ‰©å±•çš„å¹»ç¯ç‰‡")

        logger.info(f"å¼€å§‹æ‰©å±• {len(slides_to_expand)} å¼ å¹»ç¯ç‰‡")

        # å¼‚æ­¥æ‰©å±•
        expansion_task = asyncio.create_task(
            knowledge_agent.expand_multiple_slides(slides_to_expand)
        )

        # ç­‰å¾…æ‰©å±•å®Œæˆ
        try:
            expanded_results = await asyncio.wait_for(
                expansion_task,
                timeout=600.0
            )
        except asyncio.TimeoutError:
            logger.error(f"æ‰©å±•ä»»åŠ¡è¶…æ—¶")
            # å°è¯•å–æ¶ˆä»»åŠ¡
            expansion_task.cancel()
            try:
                await expansion_task
            except asyncio.CancelledError:
                pass
            raise HTTPException(status_code=408, detail="æ‰©å±•ä»»åŠ¡è¶…æ—¶ï¼Œè¯·å‡å°‘å¹»ç¯ç‰‡æ•°é‡æˆ–é‡è¯•")
        except Exception as e:
            logger.error(f"æ‰©å±•ä»»åŠ¡å¼‚å¸¸: {e}")
            raise HTTPException(status_code=500, detail=f"æ‰©å±•å¤±è´¥: {str(e)}")

        # ä¿å­˜ç»“æœ
        result_id = f"{file_id}_{int(datetime.now().timestamp())}"
        expansion_results[result_id] = {
            "file_id": file_id,
            "expanded_at": datetime.now().isoformat(),
            "total_slides": len(expanded_results),
            "slides": expanded_results
        }

        # åå°ä»»åŠ¡ï¼šä¿å­˜åˆ°æ–‡ä»¶
        background_tasks.add_task(
            save_expansion_to_file,
            file_id,
            expanded_results,
            structure
        )

        return {
            "success": True,
            "result_id": result_id,
            "file_id": file_id,
            "total_expanded": len(expanded_results),
            "message": f"æˆåŠŸæ‰©å±• {len(expanded_results)} å¼ å¹»ç¯ç‰‡"
        }

    except Exception as e:
        logger.error(f"æ‰©å±•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰©å±•å¤±è´¥: {str(e)}")


@app.get("/api/expansion/{result_id}")
async def get_expansion_result(result_id: str):
    """è·å–æ‰©å±•ç»“æœ"""
    if result_id not in expansion_results:
        raise HTTPException(status_code=404, detail="æ‰©å±•ç»“æœä¸å­˜åœ¨")

    return expansion_results[result_id]


@app.get("/api/download/{file_id}")
async def download_expanded_content(
        file_id: str,
        format: str = Query("markdown", regex="^(markdown|json|html)$")
):
    """ä¸‹è½½æ‰©å±•å†…å®¹"""
    # æŸ¥æ‰¾æœ€æ–°çš„æ‰©å±•ç»“æœ
    latest_result_id = None
    latest_time = None

    for result_id, result in expansion_results.items():
        if result["file_id"] == file_id:
            result_time = datetime.fromisoformat(result["expanded_at"])
            if latest_time is None or result_time > latest_time:
                latest_time = result_time
                latest_result_id = result_id

    if not latest_result_id:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°æ‰©å±•ç»“æœ")

    result = expansion_results[latest_result_id]

    if format == "json":
        # è¿”å›JSONæ ¼å¼
        import json as json_module
        content = json_module.dumps(result, ensure_ascii=False, indent=2)
        return JSONResponse(
            content=content,
            media_type="application/json",
            headers={"Content-Disposition": f"attachment; filename={file_id}_expanded.json"}
        )

    elif format == "markdown":
        # ç”ŸæˆMarkdownæ–‡ä»¶
        markdown_path = UPLOAD_DIR / f"{file_id}_expanded.md"

        if not markdown_path.exists():
            # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œé‡æ–°ç”Ÿæˆ
            # è·å–æ–‡ä»¶ä¿¡æ¯ä»¥è·å–PPTç»“æ„
            if file_id in file_store:
                file_info = file_store[file_id]
                structure = PPTStructure(**file_info["structure"])
                await save_expansion_to_file(
                    file_id,
                    result["slides"],
                    structure
                )
            else:
                # å¦‚æœæ²¡æœ‰æ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ç©ºç»“æ„
                await save_expansion_to_file(
                    file_id,
                    result["slides"],
                    None
                )

        return FileResponse(
            path=markdown_path,
            filename=f"{file_id}_expanded.md",
            media_type="text/markdown"
        )

    else:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")


@app.post("/api/search")
async def search_content(request: SearchRequest):
    """æœç´¢PPTå†…å®¹"""
    try:
        # ç®€å•çš„å†…å­˜æœç´¢ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨å‘é‡æ•°æ®åº“ï¼‰
        search_results = []

        for file_id, file_info in file_store.items():
            structure = PPTStructure(**file_info["structure"])

            for slide in structure.slides:
                slide_text = f"{slide.title} {' '.join(slide.content)} {' '.join(slide.bullet_points)}"

                if request.query.lower() in slide_text.lower():
                    search_results.append({
                        "file_id": file_id,
                        "filename": file_info["original_filename"],
                        "slide_number": slide.slide_number,
                        "title": slide.title,
                        "content_preview": slide.content[0][:100] + "..." if slide.content else "",
                        "relevance": slide_text.lower().count(request.query.lower())
                    })

        # æŒ‰ç›¸å…³åº¦æ’åº
        search_results.sort(key=lambda x: x["relevance"], reverse=True)

        return {
            "query": request.query,
            "total_results": len(search_results),
            "results": search_results[:request.limit]
        }

    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


async def save_expansion_to_file(
        file_id: str,
        expanded_slides: List[Dict[str, Any]],
        structure: Optional[PPTStructure] = None
):
    """ä¿å­˜æ‰©å±•ç»“æœåˆ°æ–‡ä»¶"""
    try:
        markdown_path = UPLOAD_DIR / f"{file_id}_expanded.md"

        with open(markdown_path, "w", encoding="utf-8") as f:
            f.write(f"# PPTå†…å®¹æ‰©å±•ç»“æœ\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # å¦‚æœæœ‰ç»“æ„ä¿¡æ¯ï¼Œæ·»åŠ æ›´å¤šå…ƒæ•°æ®
            if structure:
                f.write(f"**åŸå§‹æ–‡ä»¶**: {structure.metadata.filename}\n")
                f.write(f"**æ€»å¹»ç¯ç‰‡æ•°**: {structure.metadata.total_slides}\n\n")

            for slide_result in expanded_slides:
                if "error" in slide_result:
                    continue

                f.write(f"## å¹»ç¯ç‰‡ {slide_result['slide_number'] + 1}: {slide_result['title']}\n\n")

                if "explanations" in slide_result and slide_result["explanations"]:
                    f.write("### ğŸ“š è¯¦ç»†è§£é‡Š\n")
                    for exp in slide_result["explanations"]:
                        f.write(f"**{exp.get('concept', 'æ¦‚å¿µ')}**\n")
                        f.write(f"{exp.get('explanation', '')}\n\n")

                if "examples" in slide_result and slide_result["examples"]:
                    f.write("### ğŸ’» ä»£ç ç¤ºä¾‹\n")
                    for exp in slide_result["examples"]:
                        f.write(f"```{exp.get('language', 'python')}\n")
                        f.write(f"{exp.get('code_example', '')}\n")
                        f.write("```\n\n")

                if "references" in slide_result and slide_result["references"]:
                    f.write("### ğŸ“– å‚è€ƒèµ„æº\n")
                    for ref in slide_result["references"]:
                        f.write(f"- **{ref.get('title', 'èµ„æº')}**: {ref.get('description', '')}\n")
                    f.write("\n")

                if "quiz_questions" in slide_result and slide_result["quiz_questions"]:
                    f.write("### â“ æµ‹éªŒé—®é¢˜\n")
                    for quiz in slide_result["quiz_questions"]:
                        f.write(f"**é—®é¢˜**: {quiz.get('question', '')}\n")
                        for opt_key, opt_value in quiz.get('options', {}).items():
                            f.write(f"{opt_key}. {opt_value}\n")
                        f.write(f"**ç­”æ¡ˆ**: {quiz.get('answer', '')}\n")
                        f.write(f"**è§£æ**: {quiz.get('explanation', '')}\n\n")

                f.write("---\n\n")

        logger.info(f"æ‰©å±•ç»“æœå·²ä¿å­˜: {markdown_path}")
        return True

    except Exception as e:
        logger.error(f"ä¿å­˜æ‰©å±•ç»“æœå¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8010,
        reload=True
    )