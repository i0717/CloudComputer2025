from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Query
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uvicorn
import os
import uuid
import json
import asyncio
from datetime import datetime
from pathlib import Path
import logging

from config import settings
from parser import ppt_parser, SlideContent, PPTStructure, SlideStructure
from agent import knowledge_agent

logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="PPTå†…å®¹æ‰©å±•æ™ºèƒ½ä½“API",
    description="åŸºäºäº‘åŸç”Ÿå’ŒLLMçš„PPTå†…å®¹æ‰©å±•ç³»ç»Ÿ",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path(settings.upload_folder)
UPLOAD_DIR.mkdir(exist_ok=True)

# å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰
file_store = {}
expansion_results = {}
hierarchy_analysis_results = {}  # æ–°å¢ï¼šå±‚çº§åˆ†æç»“æœå­˜å‚¨


# æ•°æ®æ¨¡å‹
class PPTUploadRequest(BaseModel):
    description: Optional[str] = None


class SlideExpansionRequest(BaseModel):
    slide_numbers: List[int] = Field(default_factory=list)
    expansion_types: List[str] = Field(default_factory=lambda: ["explanation", "examples", "references", "quiz"])


class SearchRequest(BaseModel):
    query: str
    limit: int = 5


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "PPTå†…å®¹æ‰©å±•æ™ºèƒ½ä½“API",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "ä¸Šä¼ PPT": "POST /api/upload",
            "è·å–æ–‡ä»¶åˆ—è¡¨": "GET /api/files",
            "è·å–æ–‡ä»¶è¯¦æƒ…": "GET /api/file/{file_id}",
            "æ‰©å±•å†…å®¹": "POST /api/expand/{file_id}",
            "æŒ‰å±‚çº§åˆ†ææ‰©å±•": "POST /api/expand-by-hierarchy/{file_id}",  # æ–°å¢
            "ä¸‹è½½ç»“æœ": "GET /api/download/{file_id}",
            "æœç´¢å†…å®¹": "POST /api/search",
            "å±‚çº§åˆ†æ": "GET /api/hierarchy/{file_id}",
            "åˆ†æå±‚çº§ç»“æ„": "POST /api/analyze-hierarchy/{file_id}"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "parser": "ready",
            "agent": "ready",
            "storage": "ready"
        }
    }


@app.post("/api/upload")
async def upload_ppt(
        file: UploadFile = File(...),
        description: Optional[str] = None
):
    """ä¸Šä¼ PPTæ–‡ä»¶"""
    try:
        logger.info(f"æ”¶åˆ°ä¸Šä¼ è¯·æ±‚: {file.filename}")

        # éªŒè¯æ–‡ä»¶ç±»å‹
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ['.pptx', '.ppt', '.pdf']:
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒPPTã€PPTXå’ŒPDFæ–‡ä»¶")

        # ç”Ÿæˆæ–‡ä»¶ID
        file_id = str(uuid.uuid4())
        filename = f"{file_id}_{file.filename}"
        file_path = UPLOAD_DIR / filename

        # ä¿å­˜æ–‡ä»¶
        file_content = await file.read()
        if len(file_content) > settings.max_upload_size:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤ªå¤§")

        with open(file_path, "wb") as buffer:
            buffer.write(file_content)

        logger.info(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")

        # è§£æPPT
        try:
            structure = ppt_parser.parse_pptx(str(file_path))

            # ä¿å­˜è§£æç»“æœ
            json_path = UPLOAD_DIR / f"{file_id}_parsed.json"
            ppt_parser.save_to_json(structure, str(json_path))

            try:
                logger.info(f"å¼€å§‹å‘é‡ç´¢å¼•: {file_id}")

                # ç´¢å¼•PPTå†…å®¹
                indexed_count = vector_db.index_file(
                    file_id=file_id,
                    slides=structure.slides,
                    structures=structure.hierarchical_structure
                )

                if indexed_count > 0:
                    vector_indexed_files.add(file_id)
                    logger.info(f"âœ… å‘é‡ç´¢å¼•å®Œæˆ: {indexed_count} å¼ å¹»ç¯ç‰‡")
                else:
                    logger.warning(f"âš ï¸ å‘é‡ç´¢å¼•å¤±è´¥æˆ–æ²¡æœ‰å†…å®¹å¯ç´¢å¼•")

            except Exception as e:
                logger.error(f"âŒ å‘é‡ç´¢å¼•å¤±è´¥: {e}")

            # å­˜å‚¨åˆ°å†…å­˜
            file_store[file_id] = {
                "file_id": file_id,
                "original_filename": file.filename,
                "file_path": str(file_path),
                "json_path": str(json_path),
                "uploaded_at": datetime.now().isoformat(),
                "file_size": len(file_content),
                "description": description,
                "structure": structure.dict()
            }

            logger.info(f"PPTè§£ææˆåŠŸ: {file_id}, {structure.metadata.total_slides} å¼ å¹»ç¯ç‰‡")
            logger.info(f"å±‚çº§ç»“æ„åˆ†æå®Œæˆ: {len(structure.hierarchical_structure)} ä¸ªç»“æ„å…ƒç´ ")

            return {
                "success": True,
                "file_id": file_id,
                "filename": file.filename,
                "total_slides": structure.metadata.total_slides,
                "outline": structure.outline[:10],  # åªè¿”å›å‰10æ¡å¤§çº²
                "hierarchical_elements": len(structure.hierarchical_structure),
                "message": "æ–‡ä»¶ä¸Šä¼ å’Œè§£ææˆåŠŸ"
            }

        except Exception as e:
            logger.error(f"PPTè§£æå¤±è´¥: {e}")
            # æ¸…ç†æ–‡ä»¶
            if file_path.exists():
                file_path.unlink()
            raise HTTPException(status_code=500, detail=f"PPTè§£æå¤±è´¥: {str(e)}")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@app.get("/api/files")
async def list_files():
    """è·å–æ–‡ä»¶åˆ—è¡¨"""
    files = []
    for file_id, file_info in file_store.items():
        files.append({
            "file_id": file_id,
            "filename": file_info["original_filename"],
            "uploaded_at": file_info["uploaded_at"],
            "total_slides": file_info["structure"]["metadata"]["total_slides"],
            "file_size": file_info["file_size"],
            "description": file_info.get("description"),
            "hierarchical_elements": len(file_info["structure"].get("hierarchical_structure", []))
        })

    # æŒ‰ä¸Šä¼ æ—¶é—´æ’åº
    files.sort(key=lambda x: x["uploaded_at"], reverse=True)

    return {"files": files}


@app.get("/api/file/{file_id}")
async def get_file_info(file_id: str):
    """è·å–æ–‡ä»¶è¯¦æƒ…"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    file_info = file_store[file_id]
    structure = PPTStructure(**file_info["structure"])

    return {
        "file_id": file_id,
        "filename": file_info["original_filename"],
        "uploaded_at": file_info["uploaded_at"],
        "file_size": file_info["file_size"],
        "description": file_info.get("description"),
        "structure": {
            "metadata": structure.metadata.dict(),
            "total_slides": structure.metadata.total_slides,
            "keywords": structure.keywords,
            "outline": structure.outline,
            "hierarchical_structure": [s.dict() for s in structure.hierarchical_structure]
        },
        "slides_preview": [
            {
                "slide_number": slide.slide_number,
                "title": slide.title,
                "content_preview": slide.content[0][:100] + "..." if slide.content else "",
                "level": slide.level
            }
            for slide in structure.slides[:10]  # åªè¿”å›å‰10å¼ é¢„è§ˆ
        ]
    }


@app.get("/api/file/{file_id}/slide/{slide_number}")
async def get_slide_detail(file_id: str, slide_number: int):
    """è·å–å•å¼ å¹»ç¯ç‰‡è¯¦æƒ…"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    file_info = file_store[file_id]
    structure = PPTStructure(**file_info["structure"])

    if slide_number < 0 or slide_number >= len(structure.slides):
        raise HTTPException(status_code=404, detail="å¹»ç¯ç‰‡ä¸å­˜åœ¨")

    slide = structure.slides[slide_number]
    return slide.dict()


@app.post("/api/expand/{file_id}")
async def expand_slides(
        file_id: str,
        request: SlideExpansionRequest,
        background_tasks: BackgroundTasks
):
    """æ‰©å±•å¹»ç¯ç‰‡å†…å®¹ - æ·»åŠ æ ¡éªŒ"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        file_info = file_store[file_id]
        structure = PPTStructure(**file_info["structure"])

        # ç¡®å®šè¦æ‰©å±•çš„å¹»ç¯ç‰‡
        if request.slide_numbers:
            slides_to_expand = [structure.slides[i] for i in request.slide_numbers
                                if 0 <= i < len(structure.slides)]
        else:
            # é»˜è®¤æ‰©å±•æ‰€æœ‰å¹»ç¯ç‰‡ï¼Œä½†é™åˆ¶æ•°é‡
            slides_to_expand = structure.slides[:20]  # é™åˆ¶æœ€å¤š20å¼ 

        if not slides_to_expand:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰å¯æ‰©å±•çš„å¹»ç¯ç‰‡")

        # æ£€æŸ¥å¹»ç¯ç‰‡å†…å®¹æ˜¯å¦æœ‰æ•ˆ
        valid_slides = []
        for slide in slides_to_expand:
            if slide.title.strip() or slide.content or slide.bullet_points:
                valid_slides.append(slide)

        if not valid_slides:
            raise HTTPException(status_code=400, detail="æ‰€æœ‰é€‰ä¸­çš„å¹»ç¯ç‰‡å†…å®¹éƒ½ä¸ºç©º")

        logger.info(f"å¼€å§‹æ‰©å±• {len(valid_slides)} å¼ æœ‰æ•ˆå¹»ç¯ç‰‡")

        # å¼‚æ­¥æ‰©å±•
        expansion_task = asyncio.create_task(
            knowledge_agent.expand_multiple_slides(valid_slides)
        )

        # ç­‰å¾…æ‰©å±•å®Œæˆ
        try:
            expanded_results = await asyncio.wait_for(
                expansion_task,
                timeout=600.0
            )

            # æ ¡éªŒæ‰©å±•ç»“æœ
            valid_results = []
            skipped_count = 0

            for result in expanded_results:
                if "error" in result or result.get("skipped"):
                    skipped_count += 1
                    logger.warning(
                        f"å¹»ç¯ç‰‡ {result.get('slide_number')} æ‰©å±•å¤±è´¥æˆ–è·³è¿‡: {result.get('error', result.get('reason', 'æœªçŸ¥åŸå› '))}")
                else:
                    valid_results.append(result)

            logger.info(f"æ‰©å±•å®Œæˆ: {len(valid_results)} æˆåŠŸ, {skipped_count} è·³è¿‡/å¤±è´¥")

        except asyncio.TimeoutError:
            logger.error(f"æ‰©å±•ä»»åŠ¡è¶…æ—¶")
            # å°è¯•å–æ¶ˆä»»åŠ¡
            expansion_task.cancel()
            try:
                await expansion_task
            except asyncio.CancelledError:
                pass
            raise HTTPException(status_code=408, detail="æ‰©å±•ä»»åŠ¡è¶…æ—¶ï¼Œè¯·å‡å°‘å¹»ç¯ç‰‡æ•°é‡æˆ–é‡è¯•")
        except Exception as e:
            logger.error(f"æ‰©å±•ä»»åŠ¡å¼‚å¸¸: {e}")
            raise HTTPException(status_code=500, detail=f"æ‰©å±•å¤±è´¥: {str(e)}")

        # ä¿å­˜ç»“æœ
        result_id = f"{file_id}_{int(datetime.now().timestamp())}"
        expansion_results[result_id] = {
            "file_id": file_id,
            "expanded_at": datetime.now().isoformat(),
            "total_slides": len(valid_slides),
            "successful_slides": len(valid_results),
            "skipped_slides": skipped_count,
            "slides": expanded_results
        }

        # åå°ä»»åŠ¡ï¼šä¿å­˜åˆ°æ–‡ä»¶
        background_tasks.add_task(
            save_expansion_to_file,
            file_id,
            expanded_results,
            structure
        )

        return {
            "success": True,
            "result_id": result_id,
            "file_id": file_id,
            "total_expanded": len(valid_slides),
            "successful": len(valid_results),
            "skipped": skipped_count,
            "message": f"æˆåŠŸæ‰©å±• {len(valid_results)} å¼ å¹»ç¯ç‰‡ï¼Œè·³è¿‡ {skipped_count} å¼ "
        }

    except Exception as e:
        logger.error(f"æ‰©å±•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰©å±•å¤±è´¥: {str(e)}")


@app.post("/api/expand-by-hierarchy/{file_id}")
async def expand_by_hierarchy(
        file_id: str,
        background_tasks: BackgroundTasks
):
    """æ ¹æ®å±‚çº§åˆ†æç»“æœæ‰©å±•å¹»ç¯ç‰‡å†…å®¹ï¼ˆåªæ‰©å±•æ­£æ–‡é¡µï¼‰"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        # è·å–å±‚çº§åˆ†æç»“æœ
        hierarchy_response = hierarchy_analysis_results.get(file_id)
        if not hierarchy_response:
            # å°è¯•é‡æ–°åˆ†æå±‚çº§
            hierarchy_response = await analyze_hierarchical_structure_internal(file_id)
            if not hierarchy_response:
                raise HTTPException(status_code=400, detail="è¯·å…ˆè¿›è¡Œå±‚çº§ç»“æ„åˆ†æ")

        # ä»å±‚çº§åˆ†æç»“æœä¸­æå–æ­£æ–‡é¡µ
        structure = hierarchy_response.get("structure", [])
        body_slides = []
        for item in structure:
            if item.get("content_type") == "æ­£æ–‡":
                slide_num = item.get("slide_number", -1)
                if slide_num >= 0 and slide_num < len(file_store[file_id]["structure"]["slides"]):
                    # è·å–å®é™…çš„å¹»ç¯ç‰‡å†…å®¹
                    ppt_structure = PPTStructure(**file_store[file_id]["structure"])
                    if slide_num < len(ppt_structure.slides):
                        body_slides.append(ppt_structure.slides[slide_num])

        if not body_slides:
            raise HTTPException(status_code=400, detail="å±‚çº§åˆ†æç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°æ­£æ–‡é¡µ")

        logger.info(f"å¼€å§‹æ‰©å±• {len(body_slides)} ä¸ªæ­£æ–‡é¡µ")

        # æ‰©å±•æ­£æ–‡é¡µ
        expansion_task = asyncio.create_task(
            knowledge_agent.expand_multiple_slides(body_slides)
        )

        try:
            expanded_results = await asyncio.wait_for(
                expansion_task,
                timeout=600.0
            )
        except asyncio.TimeoutError:
            logger.error("æ‰©å±•ä»»åŠ¡è¶…æ—¶")
            expansion_task.cancel()
            try:
                await expansion_task
            except asyncio.CancelledError:
                pass
            raise HTTPException(status_code=408, detail="æ‰©å±•ä»»åŠ¡è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except Exception as e:
            logger.error(f"æ‰©å±•ä»»åŠ¡å¼‚å¸¸: {e}")
            raise HTTPException(status_code=500, detail=f"æ‰©å±•å¤±è´¥: {str(e)}")

        # ä¿å­˜ç»“æœ
        result_id = f"{file_id}_hierarchy_{int(datetime.now().timestamp())}"
        expansion_results[result_id] = {
            "file_id": file_id,
            "expanded_at": datetime.now().isoformat(),
            "total_slides": len(expanded_results),
            "body_slides_count": len(body_slides),
            "expansion_type": "hierarchy_based",
            "slides": expanded_results
        }

        # åå°ä¿å­˜åˆ°æ–‡ä»¶
        file_info = file_store[file_id]
        structure = PPTStructure(**file_info["structure"])
        background_tasks.add_task(
            save_hierarchy_expansion_to_file,
            file_id,
            expanded_results,
            structure,
            hierarchy_response
        )

        return {
            "success": True,
            "result_id": result_id,
            "file_id": file_id,
            "total_body_slides": len(body_slides),
            "total_expanded": len(expanded_results),
            "expansion_type": "hierarchy_based",
            "message": f"æˆåŠŸæ‰©å±• {len(expanded_results)} ä¸ªæ­£æ–‡é¡µ"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ ¹æ®å±‚çº§åˆ†ææ‰©å±•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰©å±•å¤±è´¥: {str(e)}")


@app.get("/api/expansion/{result_id}")
async def get_expansion_result(result_id: str):
    """è·å–æ‰©å±•ç»“æœ"""
    if result_id not in expansion_results:
        raise HTTPException(status_code=404, detail="æ‰©å±•ç»“æœä¸å­˜åœ¨")

    return expansion_results[result_id]


@app.get("/api/download/{file_id}")
async def download_expanded_content(
        file_id: str,
        format: str = Query("markdown", regex="^(markdown|hierarchy_markdown|json|html)$")
):
    """ä¸‹è½½æ‰©å±•å†…å®¹"""
    # æŸ¥æ‰¾æœ€æ–°çš„æ‰©å±•ç»“æœ
    latest_result_id = None
    latest_time = None
    latest_expansion_type = None

    for result_id, result in expansion_results.items():
        if result["file_id"] == file_id:
            result_time = datetime.fromisoformat(result["expanded_at"])
            if latest_time is None or result_time > latest_time:
                latest_time = result_time
                latest_result_id = result_id
                latest_expansion_type = result.get("expansion_type", "normal")

    if not latest_result_id:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°æ‰©å±•ç»“æœ")

    result = expansion_results[latest_result_id]

    if format == "json":
        # è¿”å›JSONæ ¼å¼
        import json as json_module
        content = json_module.dumps(result, ensure_ascii=False, indent=2)
        return JSONResponse(
            content=content,
            media_type="application/json",
            headers={"Content-Disposition": f"attachment; filename={file_id}_expanded.json"}
        )

    elif format in ["markdown", "hierarchy_markdown"]:
        # ç”ŸæˆMarkdownæ–‡ä»¶
        if format == "hierarchy_markdown" and latest_expansion_type == "hierarchy_based":
            markdown_path = UPLOAD_DIR / f"{file_id}_hierarchy_expanded.md"
        else:
            markdown_path = UPLOAD_DIR / f"{file_id}_expanded.md"

        if not markdown_path.exists():
            # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œé‡æ–°ç”Ÿæˆ
            if file_id in file_store:
                file_info = file_store[file_id]
                structure = PPTStructure(**file_info["structure"])

                if format == "hierarchy_markdown" and latest_expansion_type == "hierarchy_based":
                    # è·å–å±‚çº§åˆ†æç»“æœ
                    hierarchy_result = hierarchy_analysis_results.get(file_id, {})
                    await save_hierarchy_expansion_to_file(
                        file_id,
                        result["slides"],
                        structure,
                        hierarchy_result
                    )
                else:
                    await save_expansion_to_file(
                        file_id,
                        result["slides"],
                        structure
                    )
            else:
                # å¦‚æœæ²¡æœ‰æ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ç©ºç»“æ„
                await save_expansion_to_file(
                    file_id,
                    result["slides"],
                    None
                )

        filename = f"{file_id}_hierarchy_expanded.md" if format == "hierarchy_markdown" else f"{file_id}_expanded.md"
        return FileResponse(
            path=markdown_path,
            filename=filename,
            media_type="text/markdown"
        )

    else:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")


@app.post("/api/search")
async def search_content(request: SearchRequest):
    """æœç´¢PPTå†…å®¹"""
    try:
        # ç®€å•çš„å†…å­˜æœç´¢ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨å‘é‡æ•°æ®åº“ï¼‰
        search_results = []

        for file_id, file_info in file_store.items():
            structure = PPTStructure(**file_info["structure"])

            for slide in structure.slides:
                slide_text = f"{slide.title} {' '.join(slide.content)} {' '.join(slide.bullet_points)}"

                if request.query.lower() in slide_text.lower():
                    search_results.append({
                        "file_id": file_id,
                        "filename": file_info["original_filename"],
                        "slide_number": slide.slide_number,
                        "title": slide.title,
                        "content_preview": slide.content[0][:100] + "..." if slide.content else "",
                        "relevance": slide_text.lower().count(request.query.lower())
                    })

        # æŒ‰ç›¸å…³åº¦æ’åº
        search_results.sort(key=lambda x: x["relevance"], reverse=True)

        return {
            "query": request.query,
            "total_results": len(search_results),
            "results": search_results[:request.limit]
        }

    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


@app.get("/api/hierarchy/{file_id}")
async def get_hierarchical_structure(file_id: str):
    """è·å–å±‚çº§ç»“æ„åˆ†æç»“æœ"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        file_info = file_store[file_id]
        structure = PPTStructure(**file_info["structure"])

        # å¦‚æœå†…å­˜ä¸­æœ‰åˆ†æç»“æœï¼Œç›´æ¥è¿”å›
        if file_id in hierarchy_analysis_results:
            return hierarchy_analysis_results[file_id]

        # å¦åˆ™ä»è§£æç»“æœä¸­æå–
        hierarchical_structure = [s.dict() for s in structure.hierarchical_structure]

        result = {
            "file_id": file_id,
            "filename": file_info["original_filename"],
            "total_slides": structure.metadata.total_slides,
            "structure": hierarchical_structure,
            "analyzed_at": datetime.now().isoformat()
        }

        # ç¼“å­˜ç»“æœ
        hierarchy_analysis_results[file_id] = result

        return result

    except Exception as e:
        logger.error(f"è·å–å±‚çº§ç»“æ„å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å±‚çº§ç»“æ„å¤±è´¥: {str(e)}")


@app.post("/api/analyze-hierarchy/{file_id}")
async def analyze_hierarchical_structure(file_id: str):
    """é‡æ–°åˆ†æPPTçš„å±‚çº§ç»“æ„"""
    if file_id not in file_store:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        file_info = file_store[file_id]
        file_path = file_info["file_path"]

        logger.info(f"é‡æ–°åˆ†æå±‚çº§ç»“æ„: {file_id}")

        # é‡æ–°è§£æPPT
        structure = ppt_parser.parse_pptx(file_path)

        # æ›´æ–°å­˜å‚¨ä¸­çš„ç»“æ„
        file_info["structure"] = structure.dict()
        file_store[file_id] = file_info

        # ä¿å­˜æ›´æ–°åçš„è§£æç»“æœ
        json_path = UPLOAD_DIR / f"{file_id}_parsed.json"
        ppt_parser.save_to_json(structure, str(json_path))

        # æ›´æ–°å±‚çº§åˆ†æç»“æœ
        hierarchical_structure = [s.dict() for s in structure.hierarchical_structure]
        result = {
            "file_id": file_id,
            "filename": file_info["original_filename"],
            "total_slides": structure.metadata.total_slides,
            "structure": hierarchical_structure,
            "analyzed_at": datetime.now().isoformat()
        }

        hierarchy_analysis_results[file_id] = result

        logger.info(f"å±‚çº§ç»“æ„åˆ†æå®Œæˆ: {len(hierarchical_structure)} ä¸ªç»“æ„å…ƒç´ ")

        return {
            "success": True,
            "message": f"æˆåŠŸåˆ†æ {len(hierarchical_structure)} ä¸ªç»“æ„å…ƒç´ ",
            "result": result
        }

    except Exception as e:
        logger.error(f"å±‚çº§ç»“æ„åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å±‚çº§ç»“æ„åˆ†æå¤±è´¥: {str(e)}")


async def analyze_hierarchical_structure_internal(file_id: str):
    """å†…éƒ¨å±‚çº§åˆ†æå‡½æ•°"""
    try:
        file_info = file_store[file_id]
        file_path = file_info["file_path"]

        # è§£æPPT
        structure = ppt_parser.parse_pptx(file_path)

        # æ›´æ–°å­˜å‚¨ä¸­çš„ç»“æ„
        file_info["structure"] = structure.dict()
        file_store[file_id] = file_info

        # ä¿å­˜æ›´æ–°åçš„è§£æç»“æœ
        json_path = UPLOAD_DIR / f"{file_id}_parsed.json"
        ppt_parser.save_to_json(structure, str(json_path))

        # åˆ›å»ºå±‚çº§åˆ†æç»“æœ
        hierarchical_structure = [s.dict() for s in structure.hierarchical_structure]
        result = {
            "file_id": file_id,
            "filename": file_info["original_filename"],
            "total_slides": structure.metadata.total_slides,
            "structure": hierarchical_structure,
            "analyzed_at": datetime.now().isoformat()
        }

        hierarchy_analysis_results[file_id] = result
        return result

    except Exception as e:
        logger.error(f"å†…éƒ¨å±‚çº§åˆ†æå¤±è´¥: {e}")
        return None


async def save_expansion_to_file(
        file_id: str,
        expanded_slides: List[Dict[str, Any]],
        structure: Optional[PPTStructure] = None
):
    """ä¿å­˜æ‰©å±•ç»“æœåˆ°æ–‡ä»¶"""
    try:
        markdown_path = UPLOAD_DIR / f"{file_id}_expanded.md"

        with open(markdown_path, "w", encoding="utf-8") as f:
            f.write(f"# PPTå†…å®¹æ‰©å±•ç»“æœ\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # å¦‚æœæœ‰ç»“æ„ä¿¡æ¯ï¼Œæ·»åŠ æ›´å¤šå…ƒæ•°æ®
            if structure:
                f.write(f"**åŸå§‹æ–‡ä»¶**: {structure.metadata.filename}\n")
                f.write(f"**æ€»å¹»ç¯ç‰‡æ•°**: {structure.metadata.total_slides}\n\n")

            for slide_result in expanded_slides:
                if "error" in slide_result:
                    continue

                f.write(f"## å¹»ç¯ç‰‡ {slide_result['slide_number'] + 1}: {slide_result['title']}\n\n")

                # ã€ä¿®å¤1ã€‘æ¸…ç†é‡å¤çš„"è¯¦ç»†è§£é‡Š"æ ‡é¢˜
                if "explanations" in slide_result and slide_result["explanations"]:
                    f.write("### ğŸ“š è¯¦ç»†è§£é‡Š\n\n")
                    for exp in slide_result["explanations"]:
                        # é¿å…é‡å¤æ˜¾ç¤ºæ¦‚å¿µæ ‡ç­¾
                        concept = exp.get('concept', '')
                        explanation = exp.get('explanation', '')

                        # å¦‚æœæ¦‚å¿µä¸æ˜¯"è¯¦ç»†è§£é‡Š"ï¼Œæ‰æ˜¾ç¤º
                        if concept and concept not in ["è¯¦ç»†è§£é‡Š", "åŸºæœ¬è§£é‡Š", "è§£é‡Š"]:
                            f.write(f"**{concept}**\n\n")

                        f.write(f"{explanation}\n\n")

                # ã€ä¿®å¤2ã€‘ç¡®ä¿çŸ¥è¯†æ·±åº¦æ¢ç´¢å†…å®¹å®Œæ•´ä¿å­˜
                if "extended_readings" in slide_result and slide_result["extended_readings"]:
                    f.write("### ğŸ§  çŸ¥è¯†æ·±åº¦æ¢ç´¢\n\n")
                    for reading in slide_result["extended_readings"]:
                        # ä½¿ç”¨display_nameæˆ–é»˜è®¤åç§°
                        display_name = reading.get('display_name', 'çŸ¥è¯†æ·±åº¦æ¢ç´¢')
                        f.write(f"#### {reading.get('title', display_name)}\n\n")

                        # ã€å…³é”®ä¿®å¤ã€‘ä¿å­˜å®Œæ•´çš„çŸ¥è¯†æ·±åº¦æ¢ç´¢å†…å®¹
                        content = reading.get('content', '')
                        if content:
                            # æ¸…ç†å¯èƒ½çš„é‡å¤æ ‡é¢˜
                            content_lines = content.split('\n')
                            cleaned_content = []
                            seen_headers = set(['çŸ¥è¯†æ·±åº¦æ¢ç´¢', 'çŸ¥è¯†æ·±åº¦æ‰©å±•', 'å†å²èƒŒæ™¯ä¸å‘å±•',
                                                'å®é™…åº”ç”¨æ¡ˆä¾‹', 'å‰æ²¿è¿›å±•ä¸è¶‹åŠ¿', 'æ·±å…¥å­¦ä¹ å»ºè®®'])

                            for line in content_lines:
                                line_stripped = line.strip()
                                # è·³è¿‡é‡å¤çš„ç« èŠ‚æ ‡é¢˜ï¼ˆåé¢ä¼šç»Ÿä¸€æ·»åŠ ï¼‰
                                if any(header in line_stripped for header in seen_headers) and line_stripped.startswith(
                                        '#'):
                                    continue
                                cleaned_content.append(line)

                            f.write('\n'.join(cleaned_content))
                            f.write("\n\n")


                        # å¦‚æœæœ‰Wikipediaæ¥æºï¼Œæ˜¾ç¤ºå‡ºæ¥
                        if reading.get('wikipedia_sources'):
                            f.write("**Wikipediaæƒå¨æ¥æº**:\n")
                            for source in reading.get('wikipedia_sources', [])[:3]:
                                title = source.get('title', '')
                                url = source.get('url', '')
                                description = source.get('description', '')
                                if title and url:
                                    f.write(f"- [{title}]({url}): {description[:80]}...\n")
                            f.write("\n")


                if "examples" in slide_result and slide_result["examples"]:
                    f.write("### ğŸ’» ä»£ç ç¤ºä¾‹\n")
                    for exp in slide_result["examples"]:
                        f.write(f"```{exp.get('language', 'python')}\n")
                        f.write(f"{exp.get('code_example', '')}\n")
                        f.write("```\n\n")

                if "references" in slide_result and slide_result["references"]:
                    f.write("### ğŸ“– å‚è€ƒèµ„æº\n")
                    for ref in slide_result["references"]:
                        f.write(f"- **{ref.get('title', 'èµ„æº')}**: {ref.get('description', '')}\n")
                    f.write("\n")

                if "quiz_questions" in slide_result and slide_result["quiz_questions"]:
                    f.write("### â“ æµ‹éªŒé—®é¢˜\n")
                    for quiz in slide_result["quiz_questions"]:
                        f.write(f"**é—®é¢˜**: {quiz.get('question', '')}\n")
                        for opt_key, opt_value in quiz.get('options', {}).items():
                            f.write(f"{opt_key}. {opt_value}\n")
                        f.write(f"**ç­”æ¡ˆ**: {quiz.get('answer', '')}\n")
                        f.write(f"**è§£æ**: {quiz.get('explanation', '')}\n\n")

                # æ˜¾ç¤ºæ‰©å±•è´¨é‡ä¿¡æ¯
                if slide_result.get("validation_score") is not None:
                    score = slide_result["validation_score"]
                    if score >= 0.8:
                        quality = "âœ… ä¼˜ç§€"
                    elif score >= 0.6:
                        quality = "âš ï¸ è‰¯å¥½"
                    else:
                        quality = "âŒ éœ€è¦æ”¹è¿›"

                    f.write(f"**æ‰©å±•è´¨é‡**: {quality} (å¾—åˆ†: {score:.2f})\n")

                    # æ˜¾ç¤ºæ ¡éªŒæ‘˜è¦
                    if slide_result.get("validation_summary"):
                        validation = slide_result["validation_summary"]
                        if validation.get("extended_reading", {}).get("passed"):
                            f.write("**çŸ¥è¯†æ·±åº¦æ¢ç´¢**: âœ… å·²é€šè¿‡æ ¡éªŒ\n")
                        else:
                            f.write("**çŸ¥è¯†æ·±åº¦æ¢ç´¢**: âš ï¸ ä½¿ç”¨é»˜è®¤å†…å®¹\n")

                f.write("---\n\n")

        logger.info(f"æ‰©å±•ç»“æœå·²ä¿å­˜: {markdown_path}")
        return True

    except Exception as e:
        logger.error(f"ä¿å­˜æ‰©å±•ç»“æœå¤±è´¥: {e}")
        return False


async def save_hierarchy_expansion_to_file(
        file_id: str,
        expanded_slides: List[Dict[str, Any]],
        structure: PPTStructure,
        hierarchy_result: Dict[str, Any]
):
    """ä¿å­˜å±‚çº§æ‰©å±•ç»“æœåˆ°æ–‡ä»¶"""
    try:
        markdown_path = UPLOAD_DIR / f"{file_id}_hierarchy_expanded.md"

        with open(markdown_path, "w", encoding="utf-8") as f:
            f.write(f"# PPTæ­£æ–‡é¡µæ‰©å±•ç»“æœï¼ˆåŸºäºå±‚çº§åˆ†æï¼‰\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # æ–‡ä»¶ä¿¡æ¯
            f.write(f"**åŸå§‹æ–‡ä»¶**: {structure.metadata.filename}\n")
            f.write(f"**æ€»å¹»ç¯ç‰‡æ•°**: {structure.metadata.total_slides}\n")
            f.write(f"**æ­£æ–‡é¡µæ•°é‡**: {len(expanded_slides)}\n")
            f.write(f"**æ‰©å±•ç±»å‹**: åŸºäºå±‚çº§åˆ†æï¼ˆåªæ‰©å±•æ­£æ–‡é¡µï¼‰\n\n")

            # å±‚çº§åˆ†ææ‘˜è¦
            if hierarchy_result and "structure" in hierarchy_result:
                total_structure = len(hierarchy_result["structure"])
                body_count = sum(1 for item in hierarchy_result["structure"]
                                 if item.get("content_type") == "æ­£æ–‡")
                f.write("## ğŸ“Š å±‚çº§åˆ†ææ‘˜è¦\n\n")
                f.write(f"- **æ€»ç»“æ„å…ƒç´ **: {total_structure}\n")
                f.write(f"- **æ­£æ–‡é¡µæ•°é‡**: {body_count}\n")
                f.write(f"- **å·²æ‰©å±•æ­£æ–‡é¡µ**: {len(expanded_slides)}\n\n")

            f.write("## ğŸ“ æ­£æ–‡é¡µæ‰©å±•å†…å®¹\n\n")

            for slide_result in expanded_slides:
                if "error" in slide_result or slide_result.get("skipped"):
                    continue

                f.write(f"### æ­£æ–‡é¡µ {slide_result['slide_number'] + 1}: {slide_result['title']}\n\n")

                if "explanations" in slide_result and slide_result["explanations"]:
                    f.write("#### ğŸ“š è¯¦ç»†è§£é‡Š\n")
                    for exp in slide_result["explanations"]:
                        f.write(f"**{exp.get('concept', 'æ¦‚å¿µ')}**\n")
                        f.write(f"{exp.get('explanation', '')}\n\n")

                if "examples" in slide_result and slide_result["examples"]:
                    f.write("#### ğŸ’» ä»£ç ç¤ºä¾‹\n")
                    for exp in slide_result["examples"]:
                        f.write(f"```{exp.get('language', 'python')}\n")
                        f.write(f"{exp.get('code_example', '')}\n")
                        f.write("```\n\n")

                # âœ… æ–°å¢ï¼šçŸ¥è¯†æ·±åº¦æ¢ç´¢éƒ¨åˆ†ï¼ˆå»¶ä¼¸é˜…è¯»ææ–™ï¼‰
                if "extended_readings" in slide_result and slide_result["extended_readings"]:
                    f.write("#### ğŸ§  çŸ¥è¯†æ·±åº¦æ¢ç´¢\n")  # âœ… ä½¿ç”¨æ–°åç§°
                    for reading in slide_result["extended_readings"]:
                        # ä½¿ç”¨display_nameæˆ–é»˜è®¤åç§°
                        display_name = reading.get('display_name', 'çŸ¥è¯†æ·±åº¦æ¢ç´¢')
                        f.write(f"**{reading.get('title', display_name)}**\n")
                        f.write(f"{reading.get('content', '')}\n\n")

                        # å¦‚æœæœ‰Wikipediaæ¥æºï¼Œæ˜¾ç¤ºå‡ºæ¥
                        if reading.get('wikipedia_sources'):
                            f.write("**Wikipediaæƒå¨æ¥æº**:\n")
                            for source in reading.get('wikipedia_sources', [])[:2]:
                                f.write(
                                    f"- [{source.get('title', '')}]({source.get('url', '')}): {source.get('description', '')[:80]}...\n")
                            f.write("\n")

                if "references" in slide_result and slide_result["references"]:
                    f.write("#### ğŸ“– å‚è€ƒèµ„æº\n")
                    for ref in slide_result["references"]:
                        f.write(f"- **{ref.get('title', 'èµ„æº')}**: {ref.get('description', '')}\n")
                    f.write("\n")

                if "quiz_questions" in slide_result and slide_result["quiz_questions"]:
                    f.write("#### â“ æµ‹éªŒé—®é¢˜\n")
                    for quiz in slide_result["quiz_questions"]:
                        f.write(f"**é—®é¢˜**: {quiz.get('question', '')}\n")
                        for opt_key, opt_value in quiz.get('options', {}).items():
                            f.write(f"{opt_key}. {opt_value}\n")
                        f.write(f"**ç­”æ¡ˆ**: {quiz.get('answer', '')}\n")
                        f.write(f"**è§£æ**: {quiz.get('explanation', '')}\n\n")

                f.write("---\n\n")

        logger.info(f"å±‚çº§æ‰©å±•ç»“æœå·²ä¿å­˜: {markdown_path}")
        return True

    except Exception as e:
        logger.error(f"ä¿å­˜å±‚çº§æ‰©å±•ç»“æœå¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8010,
        reload=True
    )
